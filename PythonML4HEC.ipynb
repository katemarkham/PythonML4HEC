{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Analysis for HEC with DNN and MLP \n",
    "#Last updated: May 16, 2024\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_id</th>\n",
       "      <th>NDVI_max</th>\n",
       "      <th>NDVI_min</th>\n",
       "      <th>DISTPA</th>\n",
       "      <th>BUILDINGDE</th>\n",
       "      <th>DISTBUILDING</th>\n",
       "      <th>DISTROADS</th>\n",
       "      <th>DISTWATER</th>\n",
       "      <th>precipitation_max</th>\n",
       "      <th>Dist_Ag</th>\n",
       "      <th>Dist_CF</th>\n",
       "      <th>HV</th>\n",
       "      <th>slope</th>\n",
       "      <th>RAIDED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1105</td>\n",
       "      <td>2.310251</td>\n",
       "      <td>-0.316098</td>\n",
       "      <td>-0.390276</td>\n",
       "      <td>1.208716</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>-0.007311</td>\n",
       "      <td>0.542950</td>\n",
       "      <td>-0.327156</td>\n",
       "      <td>-1.518134</td>\n",
       "      <td>0.932397</td>\n",
       "      <td>1.346166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1106</td>\n",
       "      <td>1.158316</td>\n",
       "      <td>0.072941</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>-0.484078</td>\n",
       "      <td>-0.340370</td>\n",
       "      <td>-0.429011</td>\n",
       "      <td>-0.340782</td>\n",
       "      <td>1.371103</td>\n",
       "      <td>1.345913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1107</td>\n",
       "      <td>0.848879</td>\n",
       "      <td>0.154333</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-0.670483</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>2.857097</td>\n",
       "      <td>-0.860476</td>\n",
       "      <td>0.146892</td>\n",
       "      <td>0.115055</td>\n",
       "      <td>1.346084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1108</td>\n",
       "      <td>2.109068</td>\n",
       "      <td>1.457296</td>\n",
       "      <td>2.091907</td>\n",
       "      <td>0.772304</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>1.901148</td>\n",
       "      <td>1.044164</td>\n",
       "      <td>0.865384</td>\n",
       "      <td>-0.340782</td>\n",
       "      <td>1.314744</td>\n",
       "      <td>0.975369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1109</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>-0.503012</td>\n",
       "      <td>4.105167</td>\n",
       "      <td>-1.885284</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>2.287614</td>\n",
       "      <td>-1.807891</td>\n",
       "      <td>0.579173</td>\n",
       "      <td>3.355080</td>\n",
       "      <td>-0.340782</td>\n",
       "      <td>-0.324148</td>\n",
       "      <td>2.159631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   km_id  NDVI_max  NDVI_min    DISTPA  BUILDINGDE  DISTBUILDING  DISTROADS  \\\n",
       "0   1105  2.310251 -0.316098 -0.390276    1.208716     -0.823016  -0.668585   \n",
       "1   1106  1.158316  0.072941 -0.619508    0.421592      0.478244  -0.668585   \n",
       "2   1107  0.848879  0.154333 -0.619508   -0.670483     -0.823016  -0.668585   \n",
       "3   1108  2.109068  1.457296  2.091907    0.772304     -0.823016  -0.668585   \n",
       "4   1109  0.013167 -0.503012  4.105167   -1.885284     -0.823016   2.287614   \n",
       "\n",
       "   DISTWATER  precipitation_max   Dist_Ag   Dist_CF        HV     slope  \\\n",
       "0  -0.007311           0.542950 -0.327156 -1.518134  0.932397  1.346166   \n",
       "1  -0.484078          -0.340370 -0.429011 -0.340782  1.371103  1.345913   \n",
       "2  -0.031810           2.857097 -0.860476  0.146892  0.115055  1.346084   \n",
       "3   1.901148           1.044164  0.865384 -0.340782  1.314744  0.975369   \n",
       "4  -1.807891           0.579173  3.355080 -0.340782 -0.324148  2.159631   \n",
       "\n",
       "   RAIDED  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "dataset=pd.read_csv(\"C:/Users/kem99059/Desktop/Zambezi/Incidents/MachineLearningAnalysis/HEC2015_2021_From_R_100m.csv\")\n",
    "print(type(dataset))\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,1:13].values\n",
    "Y = dataset.iloc[:,13].values\n",
    "\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3F1FC80D0>\n",
      "[0.6639571189880371, 0.6083915829658508]\n",
      "Score for fold 1: loss of 0.6639571189880371; accuracy of 60.83915829658508%\n",
      "[[496 217]\n",
      " [324 389]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FBF3C880>\n",
      "[0.6239559054374695, 0.692307710647583]\n",
      "Score for fold 2: loss of 0.6239559054374695; accuracy of 69.2307710647583%\n",
      "[[469 244]\n",
      " [272 441]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FC39D9A0>\n",
      "[0.6474098563194275, 0.5804196000099182]\n",
      "Score for fold 3: loss of 0.6474098563194275; accuracy of 58.04196000099182%\n",
      "[[516 197]\n",
      " [322 391]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FBF84C40>\n",
      "[0.6829016208648682, 0.5664335489273071]\n",
      "Score for fold 4: loss of 0.6829016208648682; accuracy of 56.64335489273071%\n",
      "[[456 257]\n",
      " [281 432]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FD6ADD90>\n",
      "[0.655981719493866, 0.5874125957489014]\n",
      "Score for fold 5: loss of 0.655981719493866; accuracy of 58.74125957489014%\n",
      "[[458 255]\n",
      " [267 446]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FF1E4CA0>\n",
      "[0.6758930087089539, 0.5874125957489014]\n",
      "Score for fold 6: loss of 0.6758930087089539; accuracy of 58.74125957489014%\n",
      "[[460 253]\n",
      " [269 444]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FDAC8850>\n",
      "[0.7455663084983826, 0.47887325286865234]\n",
      "Score for fold 7: loss of 0.7455663084983826; accuracy of 47.887325286865234%\n",
      "[[456 257]\n",
      " [287 426]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FBE68790>\n",
      "[0.6504365801811218, 0.6478873491287231]\n",
      "Score for fold 8: loss of 0.6504365801811218; accuracy of 64.78873491287231%\n",
      "[[486 227]\n",
      " [264 449]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FAC16EB0>\n",
      "[0.6460241675376892, 0.6338028311729431]\n",
      "Score for fold 9: loss of 0.6460241675376892; accuracy of 63.38028311729431%\n",
      "[[489 224]\n",
      " [277 436]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C3FD5D7EE0>\n",
      "[0.6570031642913818, 0.5985915660858154]\n",
      "Score for fold 10: loss of 0.6570031642913818; accuracy of 59.85915660858154%\n",
      "[[486 227]\n",
      " [280 433]]\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 0.6570031642913818 - Accuracy: 59.85915660858154%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 59.81532633304596 (+- 5.33793163106717)\n",
      "> Loss: 0.6649129450321197\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#kfold from \n",
    "#https://github.com/christianversloot/machine-learning-articles/blob/main\n",
    "#/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "\n",
    "#############################\n",
    "#Define keras DNN model\n",
    "#############################\n",
    "\n",
    "# Model configuration\n",
    "num_folds = 10\n",
    "batch_size=200\n",
    "loss_function='binary_crossentropy'\n",
    "optimizer='AdaGrad'\n",
    "no_epochs=5000\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X,Y):\n",
    "    \n",
    " # Define the model architecture    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=12, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "   # Compile the model\n",
    "    model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(X[train], Y[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=0)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    print(model)\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(scores)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Make predictions using test data\n",
    "    p_pred = model.predict(X)\n",
    "    p_pred = p_pred.flatten()\n",
    "    y_pred = np.where(p_pred > 0.5, 1, 0)\n",
    "    #print(predictions)\n",
    "    #Generate confusion matrices\n",
    "    print(confusion_matrix(Y,y_pred))\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 325\n",
      "Trainable params: 325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Summarize the DNN model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.644460\n",
      "Precision: 0.656061\n",
      "Recall: 0.607293\n",
      "F1 score: 0.630736\n",
      "Cohens kappa: 0.288920\n",
      "ROC AUC: 0.644460\n",
      "[[486 227]\n",
      " [280 433]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# predict probabilities for test set\n",
    "yhat_probs = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(Y, yhat_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(Y, yhat_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(Y, yhat_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "#Neural networks with Multi-layer Perceptron classifier\n",
    "#######\n",
    "#Import data\n",
    "dataset=pd.read_csv(\"C:/Users/kem99059/Desktop/Zambezi/Incidents/MachineLearningAnalysis/HEC2015_2021_From_R_100m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,1:13].values\n",
    "Y = dataset.iloc[:,13].values\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[1 0 0 ... 1 1 1]\n",
      "[[654  59]\n",
      " [ 13 700]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[706   7]\n",
      " [ 73 640]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[667  46]\n",
      " [ 36 677]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[669  44]\n",
      " [ 49 664]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[627  86]\n",
      " [  6 707]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[706   7]\n",
      " [ 86 627]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[706   7]\n",
      " [ 98 615]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[626  87]\n",
      " [  4 709]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[676  37]\n",
      " [ 41 672]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[709   4]\n",
      " [114 599]]\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 0.6570031642913818 - Accuracy: 59.85915660858154%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 59.81532633304596 (+- 5.33793163106717)\n",
      "> Loss: 0.6649129450321197\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#kfold from \n",
    "#https://github.com/christianversloot/machine-learning-articles/blob/main\n",
    "#/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#############################\n",
    "#Define MLP model\n",
    "#############################\n",
    "\n",
    "# Model configuration\n",
    "kf = KFold(n_splits=10)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=100000, \n",
    "                    random_state=13)\n",
    "\n",
    "#Train the MLP model\n",
    "for train_indices,test_indices in kf.split(X):\n",
    "    mlp.fit(X[train_indices], Y[train_indices.ravel()])\n",
    "\n",
    "    #Make predictions \n",
    "    predictions = mlp.predict(X)\n",
    "    print(Y)\n",
    "    print(predictions)\n",
    "    #Generate confusion matrices\n",
    "    print(confusion_matrix(Y,predictions))\n",
    "    #print(classification_report(Y,predictions))\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-96a902e339a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0myhat_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# reduce to 1d array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0myhat_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myhat_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0myhat_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myhat_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# predict probabilities for test set\n",
    "yhat_probs = (mlp.predict(X) > 0.5).astype(\"int32\")\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = (mlp.predict(X) > 0.5).astype(\"int32\")\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(Y, yhat_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(Y, yhat_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(Y, yhat_classes)\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
