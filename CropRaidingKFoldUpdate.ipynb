{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Crop raiding points from 2015-2021\n",
    "#May 16, 2024\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_id</th>\n",
       "      <th>NDVI_max</th>\n",
       "      <th>NDVI_min</th>\n",
       "      <th>DISTPA</th>\n",
       "      <th>BUILDINGDE</th>\n",
       "      <th>DISTBUILDING</th>\n",
       "      <th>DISTROADS</th>\n",
       "      <th>DISTWATER</th>\n",
       "      <th>precipitation_max</th>\n",
       "      <th>Dist_Ag</th>\n",
       "      <th>Dist_CF</th>\n",
       "      <th>HV</th>\n",
       "      <th>slope</th>\n",
       "      <th>RAIDED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1105</td>\n",
       "      <td>2.310251</td>\n",
       "      <td>-0.316098</td>\n",
       "      <td>-0.390276</td>\n",
       "      <td>1.208716</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>-0.007311</td>\n",
       "      <td>0.542950</td>\n",
       "      <td>-0.327156</td>\n",
       "      <td>-1.518134</td>\n",
       "      <td>0.932397</td>\n",
       "      <td>1.346166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1106</td>\n",
       "      <td>1.158316</td>\n",
       "      <td>0.072941</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>-0.484078</td>\n",
       "      <td>-0.340370</td>\n",
       "      <td>-0.429011</td>\n",
       "      <td>-0.340782</td>\n",
       "      <td>1.371103</td>\n",
       "      <td>1.345913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1107</td>\n",
       "      <td>0.848879</td>\n",
       "      <td>0.154333</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-0.670483</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>2.857097</td>\n",
       "      <td>-0.860476</td>\n",
       "      <td>0.146892</td>\n",
       "      <td>0.115055</td>\n",
       "      <td>1.346084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1108</td>\n",
       "      <td>2.109068</td>\n",
       "      <td>1.457296</td>\n",
       "      <td>2.091907</td>\n",
       "      <td>0.772304</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>-0.668585</td>\n",
       "      <td>1.901148</td>\n",
       "      <td>1.044164</td>\n",
       "      <td>0.865384</td>\n",
       "      <td>-0.340782</td>\n",
       "      <td>1.314744</td>\n",
       "      <td>0.975369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1109</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>-0.503012</td>\n",
       "      <td>4.105167</td>\n",
       "      <td>-1.885284</td>\n",
       "      <td>-0.823016</td>\n",
       "      <td>2.287614</td>\n",
       "      <td>-1.807891</td>\n",
       "      <td>0.579173</td>\n",
       "      <td>3.355080</td>\n",
       "      <td>-0.340782</td>\n",
       "      <td>-0.324148</td>\n",
       "      <td>2.159631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   km_id  NDVI_max  NDVI_min    DISTPA  BUILDINGDE  DISTBUILDING  DISTROADS  \\\n",
       "0   1105  2.310251 -0.316098 -0.390276    1.208716     -0.823016  -0.668585   \n",
       "1   1106  1.158316  0.072941 -0.619508    0.421592      0.478244  -0.668585   \n",
       "2   1107  0.848879  0.154333 -0.619508   -0.670483     -0.823016  -0.668585   \n",
       "3   1108  2.109068  1.457296  2.091907    0.772304     -0.823016  -0.668585   \n",
       "4   1109  0.013167 -0.503012  4.105167   -1.885284     -0.823016   2.287614   \n",
       "\n",
       "   DISTWATER  precipitation_max   Dist_Ag   Dist_CF        HV     slope  \\\n",
       "0  -0.007311           0.542950 -0.327156 -1.518134  0.932397  1.346166   \n",
       "1  -0.484078          -0.340370 -0.429011 -0.340782  1.371103  1.345913   \n",
       "2  -0.031810           2.857097 -0.860476  0.146892  0.115055  1.346084   \n",
       "3   1.901148           1.044164  0.865384 -0.340782  1.314744  0.975369   \n",
       "4  -1.807891           0.579173  3.355080 -0.340782 -0.324148  2.159631   \n",
       "\n",
       "   RAIDED  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "dataset=pd.read_csv(\"C:/Users/kem99059/Desktop/Zambezi/Incidents/MachineLearningAnalysis/HEC2015_2021_From_R_100m.csv\")\n",
    "print(type(dataset))\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,1:13].values\n",
    "Y = dataset.iloc[:,13].values\n",
    "\n",
    "#Split into training and testing\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30)\n",
    "\n",
    "#Scale stuff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E52296E80>\n",
      "[0.669442355632782, 0.6083915829658508]\n",
      "Score for fold 1: loss of 0.669442355632782; accuracy of 60.83915829658508%\n",
      "[[495 218]\n",
      " [306 407]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E557D14F0>\n",
      "[0.636203408241272, 0.6363636255264282]\n",
      "Score for fold 2: loss of 0.636203408241272; accuracy of 63.63636255264282%\n",
      "[[430 283]\n",
      " [218 495]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E522D7B80>\n",
      "[0.6458246111869812, 0.6153846383094788]\n",
      "Score for fold 3: loss of 0.6458246111869812; accuracy of 61.538463830947876%\n",
      "[[529 184]\n",
      " [336 377]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E55A02970>\n",
      "[0.6856989860534668, 0.5804196000099182]\n",
      "Score for fold 4: loss of 0.6856989860534668; accuracy of 58.04196000099182%\n",
      "[[470 243]\n",
      " [284 429]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E57057EB0>\n",
      "[0.6528745889663696, 0.6293706297874451]\n",
      "Score for fold 5: loss of 0.6528745889663696; accuracy of 62.93706297874451%\n",
      "[[502 211]\n",
      " [277 436]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E47796850>\n",
      "[0.6745840311050415, 0.559440553188324]\n",
      "Score for fold 6: loss of 0.6745840311050415; accuracy of 55.9440553188324%\n",
      "[[439 274]\n",
      " [245 468]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E54EBB0A0>\n",
      "[0.6780821681022644, 0.5985915660858154]\n",
      "Score for fold 7: loss of 0.6780821681022644; accuracy of 59.85915660858154%\n",
      "[[465 248]\n",
      " [282 431]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E5560D130>\n",
      "[0.6714388132095337, 0.591549277305603]\n",
      "Score for fold 8: loss of 0.6714388132095337; accuracy of 59.1549277305603%\n",
      "[[488 225]\n",
      " [266 447]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E55D35BB0>\n",
      "[0.6286165118217468, 0.6619718074798584]\n",
      "Score for fold 9: loss of 0.6286165118217468; accuracy of 66.19718074798584%\n",
      "[[520 193]\n",
      " [301 412]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021E5528E130>\n",
      "[0.6399178504943848, 0.6549295783042908]\n",
      "Score for fold 10: loss of 0.6399178504943848; accuracy of 65.49295783042908%\n",
      "[[476 237]\n",
      " [281 432]]\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 0.6399178504943848 - Accuracy: 65.49295783042908%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 61.36412858963013 (+- 3.09690632594437)\n",
      "> Loss: 0.6582683324813843\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#kfold from \n",
    "#https://github.com/christianversloot/machine-learning-articles/blob/main\n",
    "#/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "\n",
    "#############################\n",
    "#Define keras model\n",
    "#############################\n",
    "\n",
    "# Model configuration\n",
    "num_folds = 10\n",
    "batch_size=200\n",
    "loss_function='binary_crossentropy'\n",
    "optimizer='AdaGrad'\n",
    "no_epochs=5000\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X,Y):\n",
    "    \n",
    " # Define the model architecture    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=12, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "   # Compile the model\n",
    "    model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(X[train], Y[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=0)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    print(model)\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(scores)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Make predictions using test data\n",
    "    p_pred = model.predict(X)\n",
    "    p_pred = p_pred.flatten()\n",
    "    y_pred = np.where(p_pred > 0.5, 1, 0)\n",
    "    #print(predictions)\n",
    "    #Generate confusion matrices\n",
    "    print(confusion_matrix(Y,y_pred))\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_210 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 325\n",
      "Trainable params: 325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make class predictions with the model\n",
    "#predictions = np.argmax(model.predict(X) > 0.5, axis=-1).astype(\"int32\")\n",
    "##predictions=(model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.713885\n",
      "Precision: 0.713885\n",
      "Recall: 0.713885\n",
      "F1 score: 0.713885\n",
      "Cohens kappa: 0.427770\n",
      "ROC AUC: 0.713885\n",
      "[[509 204]\n",
      " [204 509]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# predict probabilities for test set\n",
    "yhat_probs = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(Y, yhat_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(Y, yhat_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(Y, yhat_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "#Neural networks with Multi-layer Perceptron classifier\n",
    "#######\n",
    "#Import data\n",
    "dataset=pd.read_csv(\"C:/Users/kem99059/Desktop/Zambezi/Incidents/MachineLearningAnalysis/HEC2015_2021_From_R_100m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,1:13].values\n",
    "Y = dataset.iloc[:,13].values\n",
    "\n",
    "#Scale stuff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[1 0 0 ... 1 1 1]\n",
      "[[654  59]\n",
      " [ 13 700]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[706   7]\n",
      " [ 73 640]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[667  46]\n",
      " [ 36 677]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[669  44]\n",
      " [ 49 664]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[627  86]\n",
      " [  6 707]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[706   7]\n",
      " [ 86 627]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[706   7]\n",
      " [ 98 615]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[626  87]\n",
      " [  4 709]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[676  37]\n",
      " [ 41 672]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[709   4]\n",
      " [114 599]]\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 0.6399178504943848 - Accuracy: 65.49295783042908%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 61.36412858963013 (+- 3.09690632594437)\n",
      "> Loss: 0.6582683324813843\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#kfold from \n",
    "#https://github.com/christianversloot/machine-learning-articles/blob/main\n",
    "#/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#############################\n",
    "#Define MLP model\n",
    "#############################\n",
    "\n",
    "# Model configuration\n",
    "kf = KFold(n_splits=10)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=100000, \n",
    "                    random_state=13)\n",
    "\n",
    "#Train the model\n",
    "for train_indices,test_indices in kf.split(X):\n",
    "    mlp.fit(X[train_indices], Y[train_indices.ravel()])\n",
    "    #print(mlp.score(X[test_indices],Y[test_indices]))\n",
    "    \n",
    "    # Generate generalization metrics\n",
    "    #scores = mlp.evaluate(X[test], Y[test], verbose=0)\n",
    "    #print(f'Score for fold {kf}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[X]} of {scores[X]*100}%')\n",
    "    #print(scores)\n",
    "    #acc_per_fold.append(scores[1] * 100)\n",
    "    #loss_per_fold.append(scores[0])\n",
    "    #Make predictions \n",
    "    predictions = mlp.predict(X)\n",
    "    print(Y)\n",
    "    print(predictions)\n",
    "    #Generate confusion matrices\n",
    "    print(confusion_matrix(Y,predictions))\n",
    "    #print(classification_report(Y,predictions))\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions using test data\n",
    "#predictions = mlp.predict(X)\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[645  68]\n",
      " [  0 713]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95       713\n",
      "           1       0.91      1.00      0.95       713\n",
      "\n",
      "    accuracy                           0.95      1426\n",
      "   macro avg       0.96      0.95      0.95      1426\n",
      "weighted avg       0.96      0.95      0.95      1426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the model\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "#print(confusion_matrix(Y,predictions))\n",
    "#print(classification_report(Y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-96a902e339a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0myhat_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# reduce to 1d array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0myhat_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myhat_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0myhat_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myhat_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# predict probabilities for test set\n",
    "yhat_probs = (mlp.predict(X) > 0.5).astype(\"int32\")\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = (mlp.predict(X) > 0.5).astype(\"int32\")\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(Y, yhat_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(Y, yhat_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(Y, yhat_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[159  37]\n",
      " [ 54 178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       196\n",
      "           1       0.83      0.77      0.80       232\n",
      "\n",
      "    accuracy                           0.79       428\n",
      "   macro avg       0.79      0.79      0.79       428\n",
      "weighted avg       0.79      0.79      0.79       428\n",
      "\n",
      "[[517   0]\n",
      " [  2 479]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       517\n",
      "           1       1.00      1.00      1.00       481\n",
      "\n",
      "    accuracy                           1.00       998\n",
      "   macro avg       1.00      1.00      1.00       998\n",
      "weighted avg       1.00      1.00      1.00       998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the model on testing data\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "#print(confusion_matrix(y_test,predictions))\n",
    "#print(classification_report(y_test,predictions))\n",
    "\n",
    "##training data\n",
    "#predict_train = mlp.predict(X_train)\n",
    "#print(confusion_matrix(y_train,predict_train))\n",
    "#print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
